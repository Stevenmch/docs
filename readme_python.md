##  Descripci贸n general del proyecto

**Nombre del c贸digo:** Brain Function App

**Versi贸n:** 1.0

**Explicaci贸n general:**

Este c贸digo implementa una funci贸n de Azure que procesa audio, lo transcribe a texto y luego utiliza ese texto para consultar o agendar tareas. Utiliza un modelo de transcripci贸n de voz a texto (STT) basado en TensorFlow Lite y un clasificador de texto para determinar la intenci贸n del usuario (consultar o agendar).

**Qu茅 problema resuelve el c贸digo:**

El c贸digo resuelve el problema de automatizar la gesti贸n de tareas a trav茅s de la voz. Permite a los usuarios interactuar con el sistema utilizando comandos de voz, que luego se transcriben y se utilizan para consultar tareas existentes o agendar nuevas tareas.

## 锔 Visi贸n general del sistema

**Arquitectura del sistema:**

```mermaid
graph LR
    A[HttpRequest] --> B(Funci贸n Azure);
    B --> C(Descargar Audio);
    C --> D(Modelo TFLite);
    D --> E(Transcripci贸n);
    E --> F(Clasificador de Intenci贸n);
    F --> G{Consultar/Agendar};
    G -- Consultar --> H(Consultar Tareas);
    G -- Agendar --> I(Agendar Tareas);
    H --> J(Tabla de Tareas);
    I --> J;
    J --> K(HttpResponse);
```

**Tecnolog铆as utilizadas:**

*   Azure Functions
*   TensorFlow Lite
*   Transformers (pipeline)
*   pandas
*   NumPy
*   soundfile
*   azure-storage-blob
*   ds\_ctcdecoder

**Dependencias:**

*   azure-functions
*   pandas
*   numpy
*   soundfile
*   tflite-runtime
*   ds\_ctcdecoder
*   transformers
*   azure-storage-blob

**Requisitos del sistema:**

*   Cuenta de Azure con acceso a Azure Functions y Azure Blob Storage.
*   Entorno de Python 3.6 o superior.
*   Las dependencias listadas deben estar instaladas.

**Prerrequisitos:**

*   Modelo de TensorFlow Lite (`model_quantized_Revision.tflite`) entrenado para la transcripci贸n de voz a texto.
*   Archivo de alfabeto (`alphabet_ES.json`) que mapea los s铆mbolos del modelo a caracteres.
*   Archivo de alfabeto para el decodificador DeepSpeech (`alphabet_ES.txt`).
*   Archivo de scorer KenLM (`kenlm_es_n12.scorer`) para mejorar la precisi贸n de la transcripci贸n.
*   Archivo CSV (`Tabla_Tareas.csv`) almacenado en Azure Blob Storage.

##  Gu铆a de uso

**C贸mo usarlo:**

La funci贸n se activa mediante una solicitud HTTP.  El audio a transcribir debe estar previamente almacenado en Azure Blob Storage. La funci贸n descarga el audio, lo transcribe y, bas谩ndose en el texto transcrito, consulta o agenda una tarea.

**Explicaci贸n de los pasos:**

1.  **Entrada:** Solicitud HTTP con un par谩metro `name` (opcional, no usado directamente en el flujo principal). El archivo de audio `output.wav` debe estar presente en el contenedor "raw" en Azure Blob Storage.
2.  **Descarga del audio:** La funci贸n descarga el archivo de audio `output.wav` desde Azure Blob Storage al directorio `./HttpBrain/`.
3.  **Transcripci贸n:** El audio descargado se transcribe a texto utilizando el modelo de TensorFlow Lite y el decodificador DeepSpeech.
4.  **Clasificaci贸n de la intenci贸n:** El texto transcrito se clasifica utilizando un modelo de Transformers para determinar si la intenci贸n del usuario es "consultar" o "agendar".
5.  **Consulta o Agendamiento:**
    *   Si la intenci贸n es "consultar", la funci贸n busca tareas en el archivo `Tabla_Tareas.csv` que coincidan con la fecha especificada en el texto transcrito y devuelve una lista de tareas.
    *   Si la intenci贸n es "agendar", la funci贸n extrae la fecha y la tarea del texto transcrito y agrega una nueva entrada al archivo `Tabla_Tareas.csv` en Azure Blob Storage.
6.  **Salida:** La funci贸n devuelve una respuesta HTTP que contiene la lista de tareas encontradas (en caso de consulta) o un mensaje de 茅xito (en caso de agendamiento).

**Caso de uso de ejemplo:**

```python
import requests
import json

# URL de la funci贸n de Azure
url = "YOUR_AZURE_FUNCTION_URL"

# Datos para la solicitud (si es necesario, aunque el audio se espera en Blob Storage)
data = {"name": "test"}

# Enviar la solicitud POST
response = requests.post(url, data=json.dumps(data))

# Imprimir la respuesta
print(response.status_code)
print(response.text)
```

Este ejemplo asume que ya existe un archivo de audio llamado `output.wav` en el contenedor "raw" de Azure Blob Storage. La funci贸n procesar谩 este audio y devolver谩 la respuesta correspondiente.

##  Documentaci贸n de la API

Esta secci贸n no aplica ya que el c贸digo proporcionado no define una API expl铆cita con endpoints, formatos de solicitud/respuesta y autenticaci贸n/autorizaci贸n. Se trata de una funci贸n de Azure que se activa mediante HTTP, pero la l贸gica principal se centra en el procesamiento interno de audio y texto.

##  Referencias

*   **Azure Functions:** [https://docs.microsoft.com/en-us/azure/azure-functions/](https://docs.microsoft.com/en-us/azure/azure-functions/)
*   **Azure Blob Storage:** [https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction)
*   **TensorFlow Lite:** [https://www.tensorflow.org/lite](https://www.tensorflow.org/lite)
*   **Transformers (Hugging Face):** [https://huggingface.co/transformers/](https://huggingface.co/transformers/)
*   **DeepSpeech:** [https://github.com/mozilla/DeepSpeech](https://github.com/mozilla/DeepSpeech)
*   **KenLM:** [https://github.com/kpu/kenlm](https://github.com/kpu/kenlm)
